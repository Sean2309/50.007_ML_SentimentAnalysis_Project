{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Helper variables to be used later\n",
    "\n",
    "labelList = [\"O\", \"B-positive\", \"B-negative\", \"B-neutral\", \"I-positive\", \"I-negative\", \"I-neutral\"]\n",
    "labelDictInit = {   \n",
    "        \"START\": 0,\n",
    "        \"O\": 0,\n",
    "        \"B-positive\": 0,\n",
    "        \"B-negative\": 0,\n",
    "        \"B-neutral\": 0,\n",
    "        \"I-positive\": 0,\n",
    "        \"I-negative\": 0,\n",
    "        \"I-neutral\": 0,\n",
    "        \"END\": 0\n",
    "    }\n",
    "\n",
    "NUMBER_OF_LABELS = len(labelList)\n",
    "\n",
    "# Initialise a random number generator with a fixed seed for reproducible results and deterministic behavior\n",
    "rng = np.random.default_rng(1004519 + 1004103 + 1004555)\n",
    "\n",
    "# Defining the filePath for the datasets\n",
    "folderPath = os.path.abspath(os.getcwd())\n",
    "\n",
    "EsTrainFilePath = os.path.join(folderPath, \"../Data/ES/train\")\n",
    "EsTrain1FilePath = os.path.join(folderPath, \"../Data/ES/train1\")\n",
    "EsDevInFilePath = os.path.join(folderPath, \"../Data/ES/dev.in\")\n",
    "EsDevOutFilePath = os.path.join(folderPath, \"../Data/ES/dev.out\")\n",
    "EsPredOutputFilePath = os.path.join(folderPath, \"../Data/ES/dev.p1.out\")\n",
    "\n",
    "RuTrainFilePath = os.path.join(folderPath, \"../Data/RU/train\")\n",
    "RuDevInFilePath = os.path.join(folderPath, \"../Data/RU/dev.in\")\n",
    "RuDevOutFilePath = os.path.join(folderPath, \"../Data/RU/dev.out\")\n",
    "RuPredOutputFilePath = os.path.join(folderPath, \"../Data/RU/dev.p1.out\")\n",
    "\n",
    "ES = [\n",
    "    EsTrainFilePath,\n",
    "    labelDictInit,\n",
    "    EsDevInFilePath,\n",
    "    EsDevOutFilePath,\n",
    "    EsPredOutputFilePath]\n",
    "\n",
    "RU = [\n",
    "    RuTrainFilePath,\n",
    "    labelDictInit,\n",
    "    RuDevInFilePath,\n",
    "    RuDevOutFilePath,\n",
    "    RuPredOutputFilePath]\n",
    "\n",
    "languages = [ES, RU]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to read and parse data\n",
    "def readFile(filePath: str):\n",
    "    with open(filePath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.readlines()\n",
    "    \n",
    "def processFile(file: list):\n",
    "    return [word[:len(word)-1] for word in file]\n",
    "\n",
    "def getAllUniqueTokens(input_data):\n",
    "    # Might want to somehow ensure that this order stays consistent between runs\n",
    "    return list(set(item.split(\" \")[0] for item in input_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "1. Write a function that estimates the emission parameters from the training set using MLE (maximum likelihood estimation):\n",
    "<br>\n",
    "$$\n",
    "e(x|y) = \\frac{{\\text{{Count}}(y \\rightarrow x)}}{{\\text{{Count}}(y)}}\n",
    "$$\n",
    "\n",
    "2. Set k to 1, implement this fix into your function for computing the emission parameters\n",
    "\n",
    "$$\n",
    "e(x|y) = \\begin{cases}\n",
    "\\frac{{\\text{{Count}}(y \\rightarrow x)}}{{\\text{{Count}}(y)+k}}, & \\text{{if the word token }} x \\text{{ appears in the training set}} \\\\\n",
    "\\frac{k}{{\\text{{Count}}(y)+k}}, & \\text{{if word token }} x \\text{{ is the special token \\#UNK\\#}}\n",
    "\\end{cases}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Emissions Function\n",
    "\n",
    "def calcCountofEachWord(file: list, labelDict_in: dict):\n",
    "    tokenDict_out = {}\n",
    "\n",
    "    for i in range(len(file)):\n",
    "        if file[i] != \"\":\n",
    "            l = file[i].split()\n",
    "            token = l[0]\n",
    "            label = l[1]\n",
    "            key = (token, label)\n",
    "            if label in labelDict_in:\n",
    "                labelDict_in[label] += 1\n",
    "\n",
    "            else:\n",
    "                labelDict_in[label] = 1\n",
    "                \n",
    "\n",
    "            if key in tokenDict_out:\n",
    "                tokenDict_out[key] += 1\n",
    "            else:\n",
    "                tokenDict_out[key] = 1\n",
    "    return tokenDict_out, labelDict_in\n",
    "\n",
    "def calcEmission(tokenDict_in: dict, labelDict_in: dict, uniqueTokensList_in: list, k: float = 1.0):\n",
    "    emissionDict_out = {}\n",
    "    unknownDict = {}\n",
    "\n",
    "    for token, label in tokenDict_in.keys():\n",
    "        if token not in emissionDict_out:\n",
    "            emissionDict_out[token] = {}  # Create an empty inner dictionary for the token\n",
    "        if labelDict_in[label] != 0:\n",
    "            e = tokenDict_in[(token, label)] / (labelDict_in[label] + k)\n",
    "            emissionDict_out[token][label] = e  # Update the emission value for the specific label\n",
    "\n",
    "    for key, labelCount in labelDict_in.items():\n",
    "        if key not in [\"START\", \"END\"]:\n",
    "            # Creating entry for unknown words\n",
    "            unknownToken = \"#UNK\"\n",
    "            e = k / (labelCount + k)\n",
    "            unknownDict[key] = e\n",
    "            emissionDict_out[unknownToken] = unknownDict\n",
    "\n",
    "    return emissionDict_out\n",
    "\n",
    "def getLabel(tokenInput: str, uniqueTokensList_in: list, emissionsDict_in: dict):\n",
    "    if tokenInput in uniqueTokensList_in:\n",
    "        x = max(emissionsDict_in[tokenInput], key=emissionsDict_in[tokenInput].get)\n",
    "        # print('x -> {tokenInput} Current max probability is: ', x)\n",
    "        return x\n",
    "    else:\n",
    "        y = max(emissionsDict_in[\"#UNK\"], key=emissionsDict_in[\"#UNK\"].get)\n",
    "        # print(f'y -> {tokenInput} Current max probability is: {y}')\n",
    "        return y\n",
    "\n",
    "def calcSentimentAnalysis(tokenList: list, trainedData: dict, uniqueTokensList_in: list):\n",
    "\n",
    "    predictedTokenList = []\n",
    "\n",
    "    for token in tokenList:\n",
    "        if token:\n",
    "            if token in trainedData:\n",
    "                predictedTokenList.append(token + \" \" + getLabel(token, uniqueTokensList_in, trainedData))\n",
    "            else:\n",
    "                predictedTokenList.append(token + \" \" + getLabel(token, uniqueTokensList_in, trainedData))\n",
    "        else:\n",
    "            predictedTokenList.append(\"\")\n",
    "    return predictedTokenList\n",
    "\n",
    "\n",
    "def evalModel(predictedTokenFilePath: str, actualTokenFilePath: str):\n",
    "    \n",
    "    # Reading both files\n",
    "    predictedTokenFile = processFile(readFile(predictedTokenFilePath))\n",
    "    actualTokenFile = processFile(readFile(actualTokenFilePath))\n",
    "\n",
    "    # print(\"\\n=============Processed Files=============\")\n",
    "    # print(f\"Predicted Token File: {predictedTokenFile}\")\n",
    "    # print(f\"Actual Token File: {actualTokenFile}\")\n",
    "    # print(\"=============Processed Files=============\\n\")\n",
    "\n",
    "    # Extracting the predicted and actual labels\n",
    "    predictedLabels = [line.split()[1] for line in predictedTokenFile if line]\n",
    "    actualLabels = [line.split()[1] for line in actualTokenFile if line]\n",
    "\n",
    "    # print(\"\\n=============Label Lists=============\")\n",
    "    # print(f\"Predicted Labels: {predictedLabels}\")\n",
    "    # print(f\"Actual Labels: {actualLabels}\")\n",
    "    # print(\"=============Label Lists=============\\n\")\n",
    "    \n",
    "    # Checking if the shape of the label lists are the same\n",
    "    assert len(predictedLabels) == len(actualLabels) \n",
    "    \n",
    "    # Precision\n",
    "    correctPredictions = 0\n",
    "    # Calculate metrics for each label\n",
    "    totalPredicted = len(predictedLabels)\n",
    "    totalActual = len(actualLabels)\n",
    "\n",
    "    for i in range(totalPredicted):    \n",
    "        if predictedLabels[i] == actualLabels[i]:\n",
    "            correctPredictions += 1\n",
    "\n",
    "    precision = round(correctPredictions/len(predictedLabels), 5) if (totalPredicted) != 0 else 0\n",
    "\n",
    "    # Recall\n",
    "    recall = round(correctPredictions/len(actualLabels), 5) if (totalActual) != 0 else 0\n",
    "\n",
    "    # F1\n",
    "    f1 = round(2 * ((precision * recall) / (precision + recall)), 5) if ((totalPredicted) != 0 ) and ((totalActual) != 0) else 0\n",
    "\n",
    "    print(\"\\n=============Evaluation Metrics=============\")\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1: \", f1)\n",
    "    print(\"=============Evaluation Metrics=============\\n\\n\")\n",
    "\n",
    "    return precision, recall, f1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAndWrite(\n",
    "        trainFilePath: str, \n",
    "        labelDictIn: dict, \n",
    "        devInFilePath: str, \n",
    "        devOutFilePath: str,\n",
    "        predOutputFilePath: str,\n",
    "    ):\n",
    "    # Processing the file to separate line by line\n",
    "    trainData = processFile(readFile(filePath=trainFilePath))\n",
    "    uniqueTokensList = getAllUniqueTokens(trainData)\n",
    "\n",
    "    # Calculating the count of each token to the label\n",
    "    tokenDict, labelDictOut = calcCountofEachWord(trainData, labelDictIn)\n",
    "\n",
    "    # print(f\"Token Dict is: \\n{tokenDict}\")\n",
    "    # print(f\"Label Dict is: \\n{labelDictOut}\")\n",
    "\n",
    "    # Calculating the emission value for each unique token\n",
    "    emissionsDict = calcEmission(tokenDict, labelDictOut, uniqueTokensList)\n",
    "\n",
    "    # Reading test file\n",
    "    testInData = processFile(readFile(devInFilePath))\n",
    "\n",
    "    # Predicting test data\n",
    "    predictedLabels = calcSentimentAnalysis(testInData, emissionsDict, uniqueTokensList)\n",
    "\n",
    "    # Writing to file\n",
    "    with open(predOutputFilePath, \"w+\", encoding=\"utf-8\") as file:\n",
    "        for line in predictedLabels:\n",
    "            file.write(line + \"\\n\")\n",
    "\n",
    "    # Calculating Precision\n",
    "    precision, recall, f1 = evalModel(predOutputFilePath, devOutFilePath)\n",
    "\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============Evaluation Metrics=============\n",
      "Precision:  0.6308\n",
      "Recall:  0.6308\n",
      "F1:  0.6308\n",
      "=============Evaluation Metrics=============\n",
      "\n",
      "\n",
      "\n",
      "=============Evaluation Metrics=============\n",
      "Precision:  0.64228\n",
      "Recall:  0.64228\n",
      "F1:  0.64228\n",
      "=============Evaluation Metrics=============\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running the function\n",
    "for language in languages:\n",
    "    predictAndWrite(\n",
    "        language[0],\n",
    "        language[1],\n",
    "        language[2],\n",
    "        language[3],\n",
    "        language[4]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "correctFile = processFile(readFile(os.path.join(folderPath, \"correct_dev.p1.out\")))\n",
    "ourFile = processFile(readFile(os.path.join(folderPath, \"../Data/ES/dev.p1.out\")))\n",
    "\n",
    "out = []\n",
    "\n",
    "for i in range(len(correctFile)):\n",
    "    if correctFile[i] != ourFile[i]:\n",
    "        out.append( (correctFile[i], ourFile[i]))\n",
    "print(out)\n",
    "print(len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'START': {'count': 4}, 'STOP': {'count': 4}, 'O': {'count': 27, 'tokenList': ['Estuvimos', 'hace', 'poco', 'mi', 'pareja', 'y', 'yo', 'comiendo', 'y', 'resultó', 'la', 'tan', 'acogedora', 'da', 'una', 'sensación', 'de', 'bienestar', 'decoración', 'difícil', 'de', 'conseguir', 'en', 'otros', 'lugares', 'decoración', '.']}, 'B-positive': {'count': 3, 'tokenList': ['decoración', 'decoración', 'decoración']}, 'B-negative': {'count': 0, 'tokenList': []}, 'B-neutral': {'count': 0, 'tokenList': []}, 'I-positive': {'count': 0, 'tokenList': []}, 'I-negative': {'count': 0, 'tokenList': []}, 'I-neutral': {'count': 0, 'tokenList': []}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'START': {'O': 0.75,\n",
       "  'B-positive': 0.25,\n",
       "  'B-negative': 0.0,\n",
       "  'B-neutral': 0.0,\n",
       "  'I-positive': 0.0,\n",
       "  'I-negative': 0.0,\n",
       "  'I-neutral': 0.0,\n",
       "  'STOP': 0.0},\n",
       " 'O': {'O': 0.81481,\n",
       "  'B-positive': 0.07407,\n",
       "  'B-negative': 0.0,\n",
       "  'B-neutral': 0.0,\n",
       "  'I-positive': 0.0,\n",
       "  'I-negative': 0.0,\n",
       "  'I-neutral': 0.0,\n",
       "  'STOP': 0.07407},\n",
       " 'B-positive': {'O': 0.66667,\n",
       "  'B-positive': 0.0,\n",
       "  'B-negative': 0.0,\n",
       "  'B-neutral': 0.0,\n",
       "  'I-positive': 0.0,\n",
       "  'I-negative': 0.0,\n",
       "  'I-neutral': 0.0,\n",
       "  'STOP': 0.33333},\n",
       " 'B-negative': {'O': 0.0,\n",
       "  'B-positive': 0.0,\n",
       "  'B-negative': 0.0,\n",
       "  'B-neutral': 0.0,\n",
       "  'I-positive': 0.0,\n",
       "  'I-negative': 0.0,\n",
       "  'I-neutral': 0.0,\n",
       "  'STOP': 0.0},\n",
       " 'B-neutral': {'O': 0.0,\n",
       "  'B-positive': 0.0,\n",
       "  'B-negative': 0.0,\n",
       "  'B-neutral': 0.0,\n",
       "  'I-positive': 0.0,\n",
       "  'I-negative': 0.0,\n",
       "  'I-neutral': 0.0,\n",
       "  'STOP': 0.0},\n",
       " 'I-positive': {'O': 0.0,\n",
       "  'B-positive': 0.0,\n",
       "  'B-negative': 0.0,\n",
       "  'B-neutral': 0.0,\n",
       "  'I-positive': 0.0,\n",
       "  'I-negative': 0.0,\n",
       "  'I-neutral': 0.0,\n",
       "  'STOP': 0.0},\n",
       " 'I-negative': {'O': 0.0,\n",
       "  'B-positive': 0.0,\n",
       "  'B-negative': 0.0,\n",
       "  'B-neutral': 0.0,\n",
       "  'I-positive': 0.0,\n",
       "  'I-negative': 0.0,\n",
       "  'I-neutral': 0.0,\n",
       "  'STOP': 0.0},\n",
       " 'I-neutral': {'O': 0.0,\n",
       "  'B-positive': 0.0,\n",
       "  'B-negative': 0.0,\n",
       "  'B-neutral': 0.0,\n",
       "  'I-positive': 0.0,\n",
       "  'I-negative': 0.0,\n",
       "  'I-neutral': 0.0,\n",
       "  'STOP': 0.0}}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dict to count the number of START and END\n",
    "endStatesDict = {\n",
    "    'START': {'count': 0},\n",
    "    'STOP': {'count': 0}\n",
    "}\n",
    "\n",
    "for label in labelList:\n",
    "    endStatesDict[label] = {'count': 0, 'tokenList': []}\n",
    "\n",
    "# Dict -> Keys = Label, Value = Dict of Label: Count \n",
    "# => Counts the number of Transitions from Label x -> y\n",
    "transitionDict = {}\n",
    "transitionDict['START'] = {}\n",
    "for label in labelList: \n",
    "    transitionDict['START'][label] = 0\n",
    "transitionDict['START']['STOP'] = 0\n",
    "for label1 in labelList:\n",
    "    transitionDict[label1] = {}\n",
    "    for label2 in labelList:\n",
    "        transitionDict[label1][label2] = 0\n",
    "    transitionDict[label1]['STOP'] = 0\n",
    "\n",
    "# Reading the file\n",
    "file = processFile(readFile(EsTrain1FilePath))\n",
    "prevLabel = \"START\"\n",
    "\n",
    "# print(file)\n",
    "\n",
    "for line in file:\n",
    "\n",
    "    try:\n",
    "        token, label = line.split(\" \")\n",
    "        # Blank => Start and End of sentence\n",
    "        if prevLabel == \"START\":\n",
    "            currLabel = label\n",
    "\n",
    "            endStatesDict[\"START\"]['count'] += 1\n",
    "            transitionDict[\"START\"][currLabel] += 1\n",
    "            endStatesDict[currLabel][\"count\"] += 1\n",
    "            endStatesDict[currLabel][\"tokenList\"].append(token)\n",
    "\n",
    "            prevLabel = currLabel\n",
    "        else:\n",
    "            currLabel = label\n",
    "\n",
    "            transitionDict[prevLabel][currLabel] += 1\n",
    "            endStatesDict[currLabel][\"count\"] += 1\n",
    "            endStatesDict[currLabel][\"tokenList\"].append(token)\n",
    "\n",
    "            prevLabel = currLabel    \n",
    "    except:\n",
    "        # STOP\n",
    "        currLabel = \"STOP\"\n",
    "\n",
    "        endStatesDict[\"STOP\"][\"count\"] += 1\n",
    "        transitionDict[prevLabel][\"STOP\"] += 1\n",
    "\n",
    "        # Preparing to transition from STOP to START\n",
    "        prevLabel = \"START\"\n",
    "\n",
    "endStatesDict[\"STOP\"][\"count\"] += 1\n",
    "print(endStatesDict)\n",
    "\n",
    "\n",
    "calcTransitionsDict = {}\n",
    "\n",
    "for state in transitionDict.keys():\n",
    "    calcTransitionsDict[state] = {}\n",
    "    for nextState in transitionDict[state].keys():\n",
    "        try: calcTransitionsDict[state][nextState] = round(transitionDict[state][nextState] / endStatesDict[state]['count'], 5)\n",
    "        except: calcTransitionsDict[state][nextState] = 0.0\n",
    " \n",
    "calcTransitionsDict\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
